
<html>

<head>

	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>

	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.js"></script>
        <script>
		/* to use web-assembly as backend, change the backend to 'wasm' */
                tf.setBackend('webgl').then(console.log('Backend set to', tf.getBackend()));
        </script>

	<script>

	async function get_facemesh()
	{
		var canvas = document.getElementById("plot");

		/* get video stream */
		const stream = document.querySelector("video");

		/* running facemesh code */
		const model = await facemesh.load(maxFaces=1);
		const faces = await model.estimateFaces(stream);

		if(faces.length != 0)
		{
			/* loop through faces array to capture multiple faces */
			var mesh = faces[0].scaledMesh;

			console.log(mesh);

			var draw = canvas.getContext("2d");

			/* fill canvas with black background */
			draw.fillStyle = "black";
			draw.fillRect(0, 0, canvas.width, canvas.height);

			/* highlight facial landmark points on canvas board */
			draw.fillStyle = "#00FF00";

			for(i=0; i< mesh.length; i++)
			{
				var [x, y, z] = mesh[i];

				/* scale co-ordinates to fit in canvas */
				/* not required if canvas and input video stream are of same size */

				x = (x * canvas.width) / 1280;
				y = (y * canvas.height) / 720;

				draw.fillRect(Math.round(x), Math.round(y), 2, 2);
			}
		}
		else
		{
			console.log(`no faces detected..`);
		}

	}
	</script>
</head>

<body>

	<video width=640 height=480 autoplay loop>
		<source src="jim-carrey-slow.mp4" type="video/mp4">
	</video>
	<canvas width=640 height=480 id="plot"> </canvas>

	<script>
		stream = document.querySelector("video");
		for(i=0; i<250; i++)
		{
			get_facemesh();
		}
	</script>
</body>

</html>
