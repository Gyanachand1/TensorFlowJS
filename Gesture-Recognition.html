
<html>

	<head>

		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

	</head>

	<body>
		<video width=640 height=480 autoplay muted id="camera">
		</video>

		<canvas width=640 height=480 id="augmented_world"> </canvas>

		<video autoplay muted loop id="movie" style="visibility: hidden">
			<source src="frozen.mp4" type="video/mp4"> </source>
		</video>

		<script>

			// tracks position of the hand in live camera stream
			// and plays video as per hand gestures
			async function capture_hand()
			{
				// load camera stream
				const frame = document.getElementById("camera");

				// load movie stream
				const movie = document.getElementById("movie");
				movie.play();

				// prepare canvas
				const canvas = document.getElementById("augmented_world");
				const draw = canvas.getContext("2d");

				// load hand-pose model
				const model = await handpose.load();

				// default media position & size
				var x = canvas.width - 230;
				var y = 30;
				var w = 200;
				var h = 150;

				while(1)
				{
					// fill canvas with camera frame
					draw.drawImage(frame, 0, 0, width=640, height=480);

					// track hand position
					const result = await model.estimateHands(frame);

					// if hand is detected, update hand position
					if(result.length > 0)
					{
						// get hand co-ordinates
						const hand = result[0];

						// get thumb base position
						const thumb = hand.annotations.thumb;

						const thumb_x = Math.round(thumb[0][0]);
						const thumb_y = Math.round(thumb[0][1]);

						// get pinky base position
						const pinky = hand.annotations.pinky;

						const pinky_x = Math.round(pinky[0][0]);
						const pinky_y = Math.round(pinky[0][1]);

						// update media position & size as per gestures
						x = Math.min(thumb_x, pinky_x) - 20;
						y = Math.min(thumb_y, pinky_y) - 20;
						w = Math.abs(thumb_x - pinky_x) + 70;
						h = Math.abs(thumb_y - pinky_y) + 70;
					}

					// play media at given location
					draw.drawImage(movie, x, y, w, h);

					// loop to process the next frame
					await tf.nextFrame();
				}
			}

		</script>

		<script>

		function live_webcam()
		{
			// capture live video stream from web camera
			if(navigator.mediaDevices.getUserMedia)
			{
				navigator.mediaDevices.getUserMedia({video: true})
					.then(function (stream) {video.srcObject = stream; });
			}
		}

		function main()
		{
			// check if the video is loaded and ready for processing
			video = document.getElementById("camera");
			if(video.readyState == 4)
			{
				console.log("video is ready for processing..");
				capture_hand();
			}
			else
			{
				console.log("nope, not ready yet..");
				setTimeout(main, 1000/30);
			}
		}

		// capture live stream
		live_webcam();

		// run augmentation once the video is ready
		main();

	  </script>

	</body>
</html>
